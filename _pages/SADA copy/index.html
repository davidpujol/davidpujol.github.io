<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="abstract">Abstract</h2> <p>Temporal Action Localization (TAL) is a complex task that poses relevant challenges, particularly when attempting to generalize on new – unseen – domains in real-world applications. These scenarios, despite realistic, are often neglected in the literature, exposing these solutions to important performance degradation. In this work, we tackle this issue by introducing, for the first time, an approach for Unsupervised Domain Adaptation (UDA) in sparse TAL, which we refer to as Semantic Adversarial unsupervised Domain Adaptation (SADA). Our contribution is threefold: (1) we pioneer the development of a domain adaptation model that operates on realistic sparse action detection benchmarks; (2) we tackle the limitations of global-distribution alignment techniques by introducing a novel adversarial loss that is sensitive to local class distributions, ensuring finer-grained adaptation; and (3) we present a novel experimental setup, based on EpicKitchens100, that evaluates multiple types of domain shifts in a comprehensive manner. Our experimental results indicate that SADA improves the adaptation across domains when compared to fully supervised state-of-the-art and alternative UDA methods, attaining a relative performance boost of up to $14\%$.</p> <h2 id="overview">Overview</h2> <h3 id="addressing-the-problem-of-feature-misalignment-with-sada-loss">Addressing the Problem of feature-misalignment with SADA loss</h3> <p>Our work tackles the inherent challenges in Temporal Action Localization (TAL) within video understanding. TAL involves identifying actions in videos, yet variability in appearance and acquisition creates confusion between similar actions. Traditional supervised methods struggle with unseen data variations, resulting in performance declines. Our approach, Unsupervised Domain Adaptation (UDA), aims to bridge this gap by leveraging unlabelled data. However, existing methodologies align domain distributions globally, leading to feature misalignment. Our proposed adversarial loss overcomes this limitation by aligning each action’s distribution across both domains, mitigating feature misalignment and enhancing performance.</p> <p><img src="/assets/img/sada/sada_loss.png" alt="SADA loss"> </p> <h3 id="proposing-a-new-set-of-benchmarking-setups">Proposing a new set of benchmarking setups</h3> <p>The current landscape lacks suitable benchmarks to evaluate methodologies in sparse detection for TAL. Existing benchmarks don’t cover sparse detection or the simultaneous intersection of labels, crucial aspects in real-world video understanding. To address this inadequacy, we propose a comprehensive suite of 6 new benchmarks based on the EpicKitchens100 dataset. These benchmarks examine appearance and acquisition domain shifts, providing a nuanced evaluation of methodologies in handling real-world scenarios. Our proposed benchmarks aim to fill this gap, enabling a more accurate assessment of models’ adaptability to diverse and challenging domains.</p> <p><img src="/assets/img/sada/benchmarks.png" alt="New benchmarks"> </p> <h2 id="code">Code</h2> <p>The implementation of this project is publicly available <a href="https://github.com/davidpujol/SADA" rel="external nofollow noopener" target="_blank">here</a></p> <h2 id="bibtex">BibTeX</h2> <p>Citation entry will be added soon…</p> </body></html>