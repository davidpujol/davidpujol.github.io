<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Beyond Caption-Based Queries in Video Moment Retrieval | David Pujol Perich</title> <meta name="author" content="David Pujol Perich"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://davidpujol.github.io//beyond-vmr/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">David </span>Pujol Perich</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">projects</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/sada/">SADA</a> <a class="dropdown-item" href="/beyond-vmr/">Beyond caption-based queries</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Beyond Caption-Based Queries in Video Moment Retrieval</h1> <p class="post-description"></p> </header> <article> <style>.project-header{text-align:center;padding:4rem 0 2rem}.project-title{font-size:2.4rem;font-weight:800;color:#222;margin-bottom:1rem}.authors{font-size:1.2rem;margin-bottom:.5rem}.affiliations{font-size:1.05rem;color:#666;margin-bottom:2rem}.pill-links{display:flex;justify-content:center;gap:10px;flex-wrap:wrap;margin-bottom:3rem}.pill-links a{border:1px solid #444;color:#444;border-radius:30px;padding:6px 20px;font-weight:500;transition:.2s}.pill-links a:hover{background:#444;color:#fff;text-decoration:none}.section-header{font-size:1.8rem;font-weight:700;margin:4rem 0 1.5rem;border-bottom:1px solid #eaeaea;padding-bottom:10px}.content-text{font-size:1.1rem;line-height:1.8;color:#333;text-align:justify;margin-bottom:1.5rem}.figure-box{margin:2.5rem 0;text-align:center}.figure-caption{font-size:.95rem;color:#666;margin-top:15px;font-style:italic}.bibtex-box{background:#f9f9f9;padding:20px;border-radius:8px;font-family:monospace;font-size:.9rem;overflow-x:auto;border:1px solid #eee}</style> <div class="container" style="max-width: 860px;"> <div class="project-header"> <h1 class="project-title">Beyond Caption-Based Queries for Video Moment Retrieval</h1> <div class="authors"> <strong>David Pujol-Perich</strong><sup>1*</sup>, Albert Clapés<sup>1*</sup>, Dima Damen<sup>2</sup>, Sergio Escalera<sup>1</sup>, Michael Wray<sup>2</sup> </div> <div class="affiliations"> <sup>1</sup>University of Barcelona    <sup>2</sup>University of Bristol <br><small>*Equal Contribution</small> </div> <div class="venue" style="font-weight: 600; font-size: 1.3rem; color: #b31b1b; margin-top: 10px;">CVPR 2026</div> <div class="pill-links"> <a href="#">Paper</a> <a href="https://github.com/davidpujol/beyond-vmr" rel="external nofollow noopener" target="_blank">Code</a> <a href="#">ArXiv</a> <a href="#bibliography">BibTeX</a> </div> </div> <div class="figure-box"> <div class="figure-caption">We identify a significant domain gap between the descriptive captions used in VMR training and the actual search patterns of real users.</div> </div> <h2 class="section-header">Abstract</h2> <p class="content-text"> Current Video Moment Retrieval (VMR) models are primarily trained on videos paired with captions written by annotators after watching the video. This process induces a "visual bias," leading to overly descriptive and fine-grained queries that differ significantly from the more general search queries users employ in practice. In this work, we investigate the degradation of existing VMR methods when evaluated on realistic search queries. We introduce an automated under-specification pipeline to generate three new benchmarks—<strong>HD-EPIC-S1/S2, ANC-S, and YC2-S</strong>—demonstrating that current architectural designs struggle to bridge the gap between high-level intent and visual grounding. </p> <h2 class="section-header">Captions vs. Realistic Search Queries</h2> <p class="content-text"> Standard VMR benchmarks like EpicKitchens or Charades use captions that describe every visual detail (e.g., <i>"The person picks up a silver spoon with their right hand from the wooden table"</i>). In contrast, search logs reveal that humans use minimal, under-specified queries (e.g., <i>"taking a spoon"</i>). Our analysis shows that VMR performance drops by up to 40% when moving from captions to these realistic search distributions. </p> <h2 class="section-header">Automated Under-specification Pipeline</h2> <p class="content-text"> To simulate realistic user behavior without manual re-annotation, we propose an <strong>automated under-specification pipeline</strong>. By leveraging dependency parsing and LLM-driven pruning, we systematically remove visually biased modifiers (color, material, specific spatial relations) while preserving the core action-object intent. </p> <div class="figure-box"> <div class="figure-caption">Our pipeline reduces caption complexity to match the linguistic distribution of real-world search logs.</div> </div> <h2 class="section-header">Architectural Modifications</h2> <p class="content-text"> We explore how modifications to the grounding mechanism—such as <strong>Adaptive Score Refinement (ASR)</strong> and multi-scale temporal modeling—affect the model's ability to handle semantic sparsity. We find that while these modifications improve standard VMR, they are insufficient for bridging the gap to under-specified queries, suggesting a need for better latent space alignment between sparse text and dense video features. </p> <div class="figure-box"> <div class="figure-caption">Evaluated architectures include modified DETR-based and anchor-free models like Flash-VTG.</div> </div> <h2 class="section-header">Qualitative Results</h2> <p class="content-text"> Our qualitative analysis reveals that models often "over-fit" to descriptive words. For example, when "silver" is removed from a query, the model fails to localize the spoon entirely, even if the action remains clear. The following examples showcase the retrieval success and failure cases on our new HD-EPIC-S1/S2 benchmarks. </p> <div class="figure-box"> <div class="figure-caption">Comparison of localized moments between caption-based and search-based queries.</div> </div> <h2 id="bibliography" class="section-header">Bibliography</h2> <div class="bibtex-box"> @inproceedings{pujol2026beyond, title={Beyond Caption-Based Queries for Video Moment Retrieval}, author={Pujol-Perich, David and Clapés, Albert and Damen, Dima and Escalera, Sergio and Wray, Michael}, booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, year={2026} }</div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 David Pujol Perich. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 23, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>